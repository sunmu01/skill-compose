# ==============================================================================
# Executor CUDA - GPU-Accelerated Environment
# ==============================================================================
# Provides a GPU-enabled environment for deep learning and compute-intensive tasks.
#
# Based on NVIDIA CUDA 12.1 runtime with cuDNN.
#
# Included packages:
# - torch + torchvision (GPU-accelerated)
# - transformers, accelerate (optimized inference)
# - All packages from ML environment
# ==============================================================================

FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

LABEL org.opencontainers.image.title="Skills Executor - CUDA"
LABEL org.opencontainers.image.description="GPU-accelerated execution environment"
LABEL org.opencontainers.image.version="1.0.0"

WORKDIR /app

# Install Python and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-venv \
    python3-pip \
    curl \
    git \
    build-essential \
    && rm -rf /var/lib/apt/lists/* \
    && ln -s /usr/bin/python3.11 /usr/bin/python

# Upgrade pip
RUN python -m pip install --upgrade pip

# Install executor server dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install data science packages
RUN pip install --no-cache-dir \
    numpy \
    pandas \
    scipy \
    scikit-learn \
    statsmodels

# Install visualization packages
RUN pip install --no-cache-dir \
    matplotlib \
    seaborn \
    plotly \
    pillow

# Install PyTorch with CUDA support
RUN pip install --no-cache-dir \
    torch \
    torchvision \
    torchaudio \
    --index-url https://download.pytorch.org/whl/cu121

# Install NLP/Transformers with GPU optimization
RUN pip install --no-cache-dir \
    transformers \
    datasets \
    tokenizers \
    sentencepiece \
    accelerate \
    bitsandbytes

# Install additional utilities
RUN pip install --no-cache-dir \
    requests \
    httpx \
    pyyaml \
    python-dotenv \
    beautifulsoup4 \
    openpyxl \
    jupyter \
    ipykernel

# Copy executor server and kernel module
COPY executor_server.py .
COPY ipython_kernel.py .

# Environment
ENV EXECUTOR_NAME=cuda
ENV WORKSPACES_DIR=/app/workspaces
ENV PYTHONUNBUFFERED=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Create workspaces directory
RUN mkdir -p /app/workspaces

EXPOSE 62682

CMD uvicorn executor_server:app --host 0.0.0.0 --port ${EXECUTOR_PORT:-62682}
